# LLM 추론
   
1. 양자화
- installation 에러: bitsandbytes, transformers의 버전이 맞지 않아 생기는 에러는 transformers의 버전을 지정해 설치해서 해결
   ```
   pip install torch transformers==4.38.2 accelerate
   pip install bitsandbytes
   ```
   
  위 방법으로 해결될 때도 있지만, bitsandbytes가 GPU를 안 쓰는 버전으로 깔려 있을 경우!
  - 우선 cuda-python이 깔려 있는지 확인한다.
  - 기본적으로 cuda를 쓸 수 있는 환경일 경우 아래의 순서로 bitsandbytes를 깐다.
       - 설치 과정에서, 선언했는데 사용되지 않은 변수가 있다는 에러가 다수 뜨는데 기능하는 데는 문제가 없는 듯 하다.
       - 관련 사이트: https://huggingface.co/docs/bitsandbytes/main/en/installation
    ```
      apt-get install -y build-essential cmake
      git clone https://github.com/TimDettmers/bitsandbytes.git && cd bitsandbytes/
      pip install -r requirements-dev.txt
      cmake -DCOMPUTE_BACKEND=cuda -S .
      make
      pip install .
    ```
