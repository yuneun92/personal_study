# 학습 데이터 구축용 pLLM 개발 계획

### 0. 목표 정의
1. 반자동 학습 데이터 구축에 도움이 되는 파인튜닝 모델을 만든다.
2. 보안에 민감한 데이터를 쓸 수 있도록, **pLLM**으로 구현한다.

### 1. 데이터 구축

- 데이터 수집: 기계 독해 데이터셋 + 일반 긴 텍스트 데이터
    - 실제 데이터와의 aliance를 위해, 텍스트의 길이를 달리 해 수집
    - 기계 독해 데이터셋: AI 허브 ETRI에서 다음의 데이터셋을 다운받아 적절한 것을 선별
      - AI HUB
          1. 숫자연산 기계독해 데이터
          2. 행정 문서 대상 기계 독해 데이터
          3. 기술과학 문서 기계 독해 데이터
          4. 금융, 법률 문서 기계독해 데이터
          5. 기계독해 데이터
       - ETRI
            1. 법령 QA 데이터셋
            2. 멀티홉 QA 데이터셋
            3. 근거 설명 QA 데이터셋
- 질문 예시 생성: 기계 독해 데이터셋의 원본 질문 + 일반 긴 텍스트 데이터는 GPT3.5 turbo api 이용
    - 각 질문에 id, 분야, 구분(데이터셋/gpt) 태깅
- 답변 예시 생성: GPT3.5 turbo api, solar 이용 
    - 한 질문 당 답변 각각 10개
    - 각 답변에 구분(gpt / solar) 태깅
      
### 2. pLLM 파인튜닝
- 목적: 답변의 형식과 퀄리티를 학습 시킴
- backbone 모델: 아래 후보 중 택 1
    - Eluther/polyglot-ko
    - KoAlpaca
    - KoVicuna
    - 그 외 한국어 pretrained 모델 중 컴퓨팅 파워에 부합하며 기본 답변 성능이 좋은 것 (기계 독해가 가능한 수준이어야 함. solar보다 답변을 잘 해야 함)
    - 데이터셋 구축한 뒤 테스트해보고 선정하기
- 양자화: 아래 방식 중 택1
    - auto train (LoRA 방식)
    - QLoRA
    - PEQA
- 프롬프팅: 아래 방식 중 택1
    - ReAct: 구현하려면 이 방식으로 학습 데이터도 구성해야 함.
    - 일반 프롬프트 엔지니어링
